#!/usr/bin/env python3
"""
–°–∫—Ä–∏–ø—Ç –¥–ª—è –∑–∞–ø—É—Å–∫–∞ –ø–∞–π–ø–ª–∞–π–Ω–∞ –æ–±—Ä–∞–±–æ—Ç–∫–∏ –∏—Å—Ç–æ—Ä–∏—á–µ—Å–∫–∏—Ö —Ä—É–∫–æ–ø–∏—Å–µ–π
"""

import argparse
import cv2
import os
import sys
from pathlib import Path

# –î–æ–±–∞–≤–ª–µ–Ω–∏–µ –ø—É—Ç–∏ –∫ src
sys.path.insert(0, str(Path(__file__).parent))

from src import InferencePipeline
from src.segmentation_visualizer import SegmentationVisualizer

def main():
    parser = argparse.ArgumentParser(
        description="Pipeline for processing historical manuscripts"
    )
    
    parser.add_argument(
        "--image", 
        type=str, 
        required=True,
        help="Path to input manuscript image"
    )
    
    parser.add_argument(
        "--detect-model", 
        type=str, 
        default="models/v1/yolo_detect_corpus/detect_n_model/weights/best.pt",
        help="Path to text block detection model"
    )
    
    parser.add_argument(
        "--segment-model", 
        type=str, 
        default="models/v1/yolo_segment_lines/segment_n_model/weights/best.pt",
        help="Path to line segmentation model"
    )
    
    parser.add_argument(
        "--output-dir", 
        type=str, 
        default="results",
        help="Directory for output results"
    )
    
    parser.add_argument(
        "--target-size", 
        type=int, 
        default=1280,
        help="Target image size for processing"
    )
    
    parser.add_argument(
        "--no-save", 
        action="store_true",
        help="Don't save visualization, only return results"
    )
    
    args = parser.parse_args()
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ —Å—É—â–µ—Å—Ç–≤–æ–≤–∞–Ω–∏—è —Ñ–∞–π–ª–∞
    if not os.path.exists(args.image):
        print(f"‚ùå –§–∞–π–ª –Ω–µ –Ω–∞–π–¥–µ–Ω: {args.image}")
        return 1
    
    # –ü—Ä–æ–≤–µ—Ä–∫–∞ –º–æ–¥–µ–ª–µ–π
    for model_path in [args.detect_model, args.segment_model]:
        if not os.path.exists(model_path):
            print(f"‚ö†Ô∏è  –ú–æ–¥–µ–ª—å –Ω–µ –Ω–∞–π–¥–µ–Ω–∞: {model_path}")
            print("–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, —É–∫–∞–∂–∏—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –ø—É—Ç–∏ –∫ –º–æ–¥–µ–ª—è–º.")
    
    try:
        # –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞
        print("üöÄ –ò–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏—è –ø–∞–π–ø–ª–∞–π–Ω–∞...")
        pipeline = InferencePipeline(
            detect_model_path=args.detect_model,
            segment_model_path=args.segment_model,
            target_size=args.target_size
        )
        
        # –ó–∞–ø—É—Å–∫ –ø–∞–π–ø–ª–∞–π–Ω–∞
        print(f"üìÑ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∏–∑–æ–±—Ä–∞–∂–µ–Ω–∏—è: {args.image}")
        
        if args.no_save:
            # –¢–æ–ª—å–∫–æ –∏–Ω—Ñ–µ—Ä–µ–Ω—Å
            results = pipeline.run(args.image)
            print(f"‚úÖ –û–±—Ä–∞–±–æ—Ç–∫–∞ –∑–∞–≤–µ—Ä—à–µ–Ω–∞")
            print(f"   –ù–∞–π–¥–µ–Ω–æ —Ç–µ–∫—Å—Ç–æ–≤—ã—Ö –±–ª–æ–∫–æ–≤: {len(results['detect_corpuses'])}")
            
            total_lines = sum(len(corpus["segment_lines"]) 
                            for corpus in results["detect_corpuses"])
            print(f"   –ù–∞–π–¥–µ–Ω–æ —Å—Ç—Ä–æ–∫: {total_lines}")
        else:
            # –ò–Ω—Ñ–µ—Ä–µ–Ω—Å —Å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ–º
            results = pipeline.run_and_save(
                img_path=args.image,
                output_dir=args.output_dir,
                base_filename=Path(args.image).stem
            )
            print(f"‚úÖ –†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {args.output_dir}")
        
        return 0
        
    except Exception as e:
        print(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {e}")
        return 1

if __name__ == "__main__":
    sys.exit(main())